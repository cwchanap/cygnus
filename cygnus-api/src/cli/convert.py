#!/usr/bin/env python3
"""
CLI to convert a TensorFlow 1 checkpoint to TensorFlow 2 weights.
"""

import logging
import os
from pathlib import Path

import click
import tensorflow as tf

from src.app.tf2_magenta_model import create_drum_model

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

DEFAULT_CHECKPOINT_PATH = os.path.expanduser("~/.cache/drum_transcription/models/model.ckpt-569400")
DEFAULT_OUTPUT_PATH = "models/e-gmd/tf2_model.weights.h5"


def convert_tf1_checkpoint_to_tf2(checkpoint_path: str, output_path: str):
    """
    Convert TF1 checkpoint to TF2 model weights

    Args:
        checkpoint_path: Path to TF1 checkpoint (without .data/.index extensions)
        output_path: Path to save TF2 weights (.h5 file)
    """
    logger.info(f"Loading TF1 checkpoint from: {checkpoint_path}")

    # Create the TF2 model
    model = create_drum_model()
    logger.info("Created TF2 model architecture")

    # Load TF1 checkpoint
    reader = tf.compat.v1.train.NewCheckpointReader(checkpoint_path)
    var_to_shape_map = reader.get_variable_to_shape_map()

    logger.info(f"Found {len(var_to_shape_map)} variables in checkpoint")

    # Try to load weights into TF2 model
    weights_loaded = 0
    weights_dict = {}

    for var_name, shape in var_to_shape_map.items():
        try:
            # Get the tensor value
            tensor = reader.get_tensor(var_name)

            # Log some key variables for debugging
            if (
                "conv" in var_name
                or "lstm" in var_name
                or "probs" in var_name
                or "values" in var_name
            ):
                logger.info(f"  {var_name}: shape={shape}")

            # Store weights for manual assignment
            weights_dict[var_name] = tensor
            weights_loaded += 1

        except Exception as e:  # pylint: disable=broad-except
            logger.warning(f"Could not load {var_name}: {e}")

    logger.info(f"Successfully loaded {weights_loaded}/{len(var_to_shape_map)} weights")

    # Try to assign weights to TF2 model layers
    try:
        # Find and set Conv2D weights
        for layer in model.layers:
            if isinstance(layer, tf.keras.layers.Conv2D):
                layer_name = layer.name
                # Try to find matching weights in checkpoint
                for var_name, tensor in weights_dict.items():
                    if "conv" in var_name.lower() and "conv" in layer_name.lower():
                        if "weights" in var_name or "kernel" in var_name:
                            if tensor.shape == layer.kernel.shape:
                                layer.kernel.assign(tensor)
                                logger.info(f"Assigned weights to {layer_name} kernel")
                        elif "bias" in var_name:
                            if tensor.shape == layer.bias.shape:
                                layer.bias.assign(tensor)
                                logger.info(f"Assigned weights to {layer_name} bias")

            elif isinstance(layer, tf.keras.layers.Dense):
                layer_name = layer.name
                # Try to find matching weights for output layers
                for var_name, tensor in weights_dict.items():
                    if layer_name in var_name or (
                        layer_name.replace("_", "") in var_name.replace("_", "")
                    ):
                        if "weights" in var_name or "kernel" in var_name:
                            # Dense layer kernels may need transposing
                            if tensor.T.shape == layer.kernel.shape:
                                layer.kernel.assign(tensor.T)
                                logger.info(f"Assigned transposed weights to {layer_name} kernel")
                            elif tensor.shape == layer.kernel.shape:
                                layer.kernel.assign(tensor)
                                logger.info(f"Assigned weights to {layer_name} kernel")
                        elif "bias" in var_name:
                            if tensor.shape == layer.bias.shape:
                                layer.bias.assign(tensor)
                                logger.info(f"Assigned weights to {layer_name} bias")

    except Exception as e:  # pylint: disable=broad-except
        logger.error(f"Error assigning weights: {e}")
        # Continue anyway - partial weights are better than none

    # Save the TF2 model weights
    output_dir = Path(output_path).parent
    output_dir.mkdir(parents=True, exist_ok=True)

    model.save_weights(output_path)
    logger.info(f"Saved TF2 model weights to: {output_path}")

    return model


@click.command(context_settings=dict(help_option_names=["-h", "--help"]))
@click.option(
    "--checkpoint-path",
    type=str,
    default=os.path.expanduser("~/.cache/drum_transcription/models/model.ckpt-569400"),
    show_default=True,
    help="Path to TF1 checkpoint (without .data/.index extensions)",
)
@click.option(
    "--output-path",
    type=str,
    default="models/e-gmd/tf2_model.weights.h5",
    show_default=True,
    help="Path to save TF2 weights (.h5)",
)
@click.option(
    "--test/--no-test",
    default=True,
    show_default=True,
    help="Run a quick inference test after conversion",
)
@click.option(
    "-v",
    "--verbose",
    is_flag=True,
    help="Enable verbose logging",
)
def main(checkpoint_path: str, output_path: str, test: bool, verbose: bool):
    """Convert a TF1 checkpoint to TF2 weights using the drum model."""
    if verbose:
        logger.setLevel(logging.DEBUG)

    # Check if checkpoint exists
    if not os.path.exists(checkpoint_path + ".index"):
        logger.error(f"Checkpoint not found: {checkpoint_path}")
        raise SystemExit(1)

    logger.info("Starting TF1 to TF2 checkpoint conversion...")
    model = convert_tf1_checkpoint_to_tf2(checkpoint_path, output_path)

    logger.info("âœ… Conversion complete!")
    logger.info(f"TF2 weights saved to: {output_path}")

    if test:
        logger.info("Testing converted model...")
        # Conv2D expects 4D input: [batch, time, frequency, channels]
        test_input = tf.random.normal((1, 100, 229, 1))  # Add channel dimension
        try:
            outputs = model(test_input)
            logger.info("Model inference successful!")
            for key, value in outputs.items():
                logger.info(f"  {key}: shape={value.shape}")
        except Exception as e:  # pylint: disable=broad-except
            logger.error(f"Model inference failed: {e}")
            raise SystemExit(2)


if __name__ == "__main__":
    # pylint: disable=E1120
    main()
